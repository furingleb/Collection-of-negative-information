{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import nltk\n",
    "import pickle\n",
    "import chardet\n",
    "from collections import Counter\n",
    "\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and train existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate_df(df_list, drop_cols=['Unnamed: 0']):\n",
    "    \"\"\"\n",
    "        Concatenates several data frames along first axis.\n",
    "        Also generate target vector corresponding to data frame position in the list.\n",
    "        \n",
    "        drop_cols - list of column names for removing.\n",
    "    \"\"\"\n",
    "    y = []    # target vector\n",
    "    for i, df in enumerate(df_list):\n",
    "        y.extend([i] * df.shape[0])\n",
    "    \n",
    "    data = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    data.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "    return data, y\n",
    "\n",
    "\n",
    "def build_corpus(df, col_indx=0):\n",
    "    \"\"\"\n",
    "        Creates list of texts.\n",
    "        \n",
    "        col_indx - index of column that contains texts.\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    for i in range(df.shape[0]):\n",
    "        value = df.iloc[i, col_indx]\n",
    "        if type(value) == str:\n",
    "            corpus.append(value)\n",
    "        else:\n",
    "            corpus.append('')\n",
    "    return corpus\n",
    "\n",
    "\n",
    "def clear_line(line):\n",
    "    \"\"\"\n",
    "        Reading file of key words.\n",
    "    \"\"\"\n",
    "    line = line.lower()\n",
    "    line = line.replace('\\n', '')       # replace new line symbol\n",
    "    line = re.split('[,:] *', line)     # split line by ', *'\n",
    "    if line[-1] == '':                  # remove empty element in the last position\n",
    "        line.pop()\n",
    "    \n",
    "    return line\n",
    "\n",
    "\n",
    "def read_patterns_file(path_file, encoding='utf-8'):\n",
    "    \"\"\"\n",
    "        Reads file of key word patterns. Each group of patterns must be devided by empty line.\n",
    "        Return dictionary of pattern group indices and corresponding list of patterns.\n",
    "    \"\"\"\n",
    "    k = 0\n",
    "    patterns = {k: []}\n",
    "    with open(path_file, 'r', encoding=encoding) as file:\n",
    "        reader = (line for line in file.readlines())\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                line = next(reader)\n",
    "                new_line = clear_line(line)\n",
    "                \n",
    "                if len(new_line) == 0:\n",
    "                    k += 1\n",
    "                    patterns[k] = []\n",
    "                else:\n",
    "                    patterns[k].extend(new_line)\n",
    "                    \n",
    "            except Exception as error:\n",
    "                print(error)\n",
    "                break\n",
    "                \n",
    "    return patterns\n",
    "\n",
    "\n",
    "def create_add_features(corpus, patterns):\n",
    "    \"\"\"\n",
    "        Creates additional feature matrix based on cooccurance of pattern words.\n",
    "        \n",
    "        patterns - dictionary of pattern group indices and corresponding list of patterns.\n",
    "    \"\"\"\n",
    "    all_patterns = []\n",
    "    feature_names = []\n",
    "    for ptrn in patterns.values():\n",
    "        feature_names.extend(ptrn)\n",
    "        all_patterns.extend([' ' + w + ' ' for w in ptrn])\n",
    "        \n",
    "    add_matrix = [0] * len(corpus)\n",
    "    for pattern in all_patterns:\n",
    "        tmp_feature = [0] * len(corpus)\n",
    "        for i in range(len(corpus)):\n",
    "            f = len(re.findall(pattern, corpus[i]))\n",
    "            if f > 0:\n",
    "                tmp_feature[i] = f\n",
    "        add_matrix = np.vstack((add_matrix, tmp_feature))\n",
    "    \n",
    "    return add_matrix[1:, :].T, feature_names\n",
    "\n",
    "\n",
    "def batch_predict(model, df, data_encoder, feature_mask=None, patterns=None, text_col=0, batch_size=10000):\n",
    "    \"\"\"\n",
    "        Performs batch prediction mode.\n",
    "        \n",
    "        Params:\n",
    "            model        - trained model that can make classification.\n",
    "            df           - data frame which rows need to be classified.\n",
    "            data_encoder - object for encoding corpus into numbers.\n",
    "            feature_mask - bool array for feature selection.\n",
    "            patterns     - dictionary of pattern group indices and corresponding list of word patterns.\n",
    "                           Use it if you need add new features based on word patterns.\n",
    "            text_col     - column index that contains text.\n",
    "            batch_size   - number of rows for one pass.\n",
    "    \"\"\"\n",
    "    pred = []\n",
    "    for i in range(0, df.shape[0], batch_size):\n",
    "        tmp_corpus = build_corpus(df.iloc[i:i + batch_size, :], col_indx=text_col)\n",
    "        x_tmp = data_encoder.transform(tmp_corpus)\n",
    "        \n",
    "        if patterns:\n",
    "            tmp_add_features, _ = create_add_features(corpus=tmp_corpus, patterns=patterns)\n",
    "            x_tmp = np.hstack((x_tmp.toarray(), tmp_add_features))\n",
    "            \n",
    "        if type(feature_mask) == np.ndarray:\n",
    "            x_tmp = x_tmp[:, feature_mask]\n",
    "            \n",
    "        pred.extend(np.argmax(model.predict(x_tmp), axis=1))\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('df_invest_neg_morf.xlsx')\n",
    "df2 = pd.read_excel('df_pens_neg_morf.xlsx')\n",
    "df3 = pd.read_excel('df_strah_neg_morf.xlsx')\n",
    "df4 = pd.read_excel('Благо4.xlsx')\n",
    "\n",
    "df1_new = pd.read_excel('Общий файл отзывов_4_1.xlsx')\n",
    "df2_new = pd.read_excel('Общий файл отзывов_4_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# prepare data for train/test\n",
    "data, y = concate_df(df_list=[df1, df2, df3, df4])\n",
    "corpus = build_corpus(data)\n",
    "patterns = read_patterns_file(path_file='Метки.txt')\n",
    "additional_features, add_feat_names = create_add_features(corpus=corpus, patterns=patterns)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('russian')\n",
    "vectorizer = TfidfVectorizer(min_df=20, stop_words=stopwords)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "X_plus = np.hstack((X.toarray(), additional_features))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_plus, y, test_size=0.33, random_state=42)\n",
    "lgb_train = lightgbm.Dataset(X_train, y_train)\n",
    "lgb_eval = lightgbm.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds.\n",
      "[10]\tvalid_0's multi_logloss: 0.368493\n",
      "[20]\tvalid_0's multi_logloss: 0.233353\n",
      "[30]\tvalid_0's multi_logloss: 0.188921\n",
      "[40]\tvalid_0's multi_logloss: 0.169686\n",
      "[50]\tvalid_0's multi_logloss: 0.16087\n",
      "[60]\tvalid_0's multi_logloss: 0.156857\n",
      "[70]\tvalid_0's multi_logloss: 0.152883\n",
      "[80]\tvalid_0's multi_logloss: 0.151864\n",
      "[90]\tvalid_0's multi_logloss: 0.151162\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's multi_logloss: 0.151048\n",
      "\n",
      "Train duration: 6.712383985519409 s\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclassova',\n",
    "    'num_class': 4, \n",
    "    'metric': 'softmax', \n",
    "    'num_leaves': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 1.,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5, \n",
    "    'reg_alpha': 3.0, \n",
    "    'is_unbalance': True,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "gbm = lightgbm.train(params,\n",
    "                     lgb_train,\n",
    "                     num_boost_round=110,\n",
    "                     valid_sets=lgb_eval,\n",
    "                     early_stopping_rounds=10, \n",
    "                     verbose_eval=10)\n",
    "end = time.time()\n",
    "print('\\nTrain duration: {} s'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train:  0.9403156384505021\n",
      "Accuracy on test:  0.9213744903902155\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on train: ', accuracy_score(y_train, np.argmax(gbm.predict(X_train), axis=1)))\n",
    "print('Accuracy on test: ', accuracy_score(y_test, np.argmax(gbm.predict(X_test), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       344\n",
      "           1       0.78      0.90      0.83       330\n",
      "           2       0.98      0.92      0.95      1892\n",
      "           3       0.89      0.98      0.93       868\n",
      "\n",
      "    accuracy                           0.92      3434\n",
      "   macro avg       0.88      0.90      0.88      3434\n",
      "weighted avg       0.93      0.92      0.92      3434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, np.argmax(gbm.predict(X_test), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 267   10    9   58]\n",
      " [   7  297   21    5]\n",
      " [  31   72 1748   41]\n",
      " [   3    4    9  852]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, np.argmax(gbm.predict(X_test), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['фонд\\\\w*', 'электроэнерг\\\\w*', 'инвест\\\\w*', 'облиг\\\\w*',\n",
       "       'депозитар\\\\w*', 'страх\\\\w* част\\\\w*', 'накопит\\\\w* часть',\n",
       "       'перев\\\\w* пенс\\\\w*'], dtype='<U32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(add_feat_names)[(gbm.feature_importance() != 0)[-128:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train duration: 1.4820847511291504 s\n"
     ]
    }
   ],
   "source": [
    "features_mask = gbm.feature_importance() != 0\n",
    "\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_plus[:, features_mask], \n",
    "                                                            y, \n",
    "                                                            test_size=0.33, \n",
    "                                                            random_state=42)\n",
    "\n",
    "lgb_train_p = lightgbm.Dataset(X_train_p, y_train_p)\n",
    "lgb_eval_p = lightgbm.Dataset(X_test_p, y_test_p, reference=lgb_train_p)\n",
    "\n",
    "start_p = time.time()\n",
    "gbm_p = lightgbm.train(params,\n",
    "                       lgb_train_p,\n",
    "                       num_boost_round=110,\n",
    "                       valid_sets=lgb_eval_p,\n",
    "                       early_stopping_rounds=10, \n",
    "                       verbose_eval=False)\n",
    "end_p = time.time()\n",
    "\n",
    "print('Train duration: {} s'.format(end_p - start_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       344\n",
      "           1       0.77      0.90      0.83       330\n",
      "           2       0.98      0.92      0.95      1892\n",
      "           3       0.89      0.98      0.94       868\n",
      "\n",
      "    accuracy                           0.92      3434\n",
      "   macro avg       0.88      0.90      0.88      3434\n",
      "weighted avg       0.93      0.92      0.92      3434\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_p, np.argmax(gbm_p.predict(X_test_p), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = batch_predict(gbm, df1_new, vectorizer, feature_mask=None, text_col=1, patterns=patterns)\n",
    "pred2 = batch_predict(gbm, df2_new, vectorizer, feature_mask=None, text_col=1, patterns=patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({3: 38617, 1: 1611, 0: 824, 2: 3946}),\n",
       " Counter({3: 44268, 0: 715, 2: 2421, 1: 1935}))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pred1), Counter(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save the model\n",
    "#with open('classifier.pkl', 'wb') as file:\n",
    "#    pickle.dump(gbm, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save patterns dictionary\n",
    "#with open('patterns.pkl', 'wb') as file:\n",
    "#    pickle.dump(patterns, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vectorizer\n",
    "#with open('vectorizer.pkl', 'wb') as file:\n",
    "#    pickle.dump(vectorizer, file, protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "with open('classifier.pkl', 'rb') as file:\n",
    "    clf = pickle.load(file)\n",
    "    \n",
    "# load patterns\n",
    "with open('patterns.pkl', 'rb') as file:\n",
    "    ptr = pickle.load(file)\n",
    "    \n",
    "# load vectorizer\n",
    "with open('vectorizer.pkl', 'rb') as file:\n",
    "    vct = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train:  0.9403156384505021\n",
      "Accuracy on test:  0.9213744903902155\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on train: ', accuracy_score(y_train, np.argmax(clf.predict(X_train), axis=1)))\n",
    "print('Accuracy on test: ', accuracy_score(y_test, np.argmax(clf.predict(X_test), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = batch_predict(clf, df1_new, vct, feature_mask=None, text_col=1, patterns=ptr)\n",
    "pred2 = batch_predict(clf, df2_new, vct, feature_mask=None, text_col=1, patterns=ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 38617, 2: 3946, 1: 1611, 0: 824})\n",
      "Counter({3: 44268, 2: 2421, 1: 1935, 0: 715})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(pred1))\n",
    "print(Counter(pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dirty version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_excel('df_invest_neg_morf.xlsx')\n",
    "df2 = pd.read_excel('df_pens_neg_morf.xlsx')\n",
    "df3 = pd.read_excel('df_strah_neg_morf.xlsx')\n",
    "df4 = pd.read_excel('Благо4.xlsx')\n",
    "\n",
    "# target vector\n",
    "y = np.array([0] * df1.shape[0] + [1] * df2.shape[0] + [2] * df3.shape[0] + [3] * df4.shape[0])\n",
    "\n",
    "# deleting useless column\n",
    "data = pd.concat([df1, df2, df3, df4], axis=0, ignore_index=True)\n",
    "data.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "# creating bag of docs\n",
    "corpus = []\n",
    "for i in range(data.shape[0]):\n",
    "    corpus.append(data.iloc[i, 0])\n",
    "    \n",
    "    \n",
    "def clear_line(line):\n",
    "    line = line.lower()\n",
    "    line = line.replace('\\n', '')       # replace new line symbol\n",
    "    line = re.split('[,:] *', line)     # split line by ', *'\n",
    "    if line[-1] == '':                  # remove empty element in the last position\n",
    "        line.pop()\n",
    "    \n",
    "    return line\n",
    "\n",
    "\n",
    "with open('Метки.txt', 'r', encoding='utf-8') as file:\n",
    "    reader = (line for line in file.readlines())\n",
    "    k = 0\n",
    "    patterns = {k: []}\n",
    "    while True:\n",
    "        try:\n",
    "            line = next(reader)\n",
    "            new_line = clear_line(line)\n",
    "            \n",
    "            if len(new_line) == 0:\n",
    "                k += 1\n",
    "                patterns[k] = []\n",
    "            else:\n",
    "                patterns[k].extend(new_line)\n",
    "                \n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('russian')\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=20, stop_words=stopwords)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "all_patterns = []\n",
    "for part in patterns.values():\n",
    "    all_patterns.extend([' ' + w + ' ' for w in part])\n",
    "    \n",
    "add_matrix = [0] * len(corpus)\n",
    "for pattern in all_patterns:\n",
    "    tmp_feature = [0] * len(corpus)\n",
    "    for i in range(len(corpus)):\n",
    "        f = len(re.findall(pattern, corpus[i]))\n",
    "        if f > 0:\n",
    "            tmp_feature[i] = f\n",
    "    add_matrix = np.vstack((add_matrix, tmp_feature))\n",
    "    \n",
    "    \n",
    "add_matrix = add_matrix[1:, :]\n",
    "mtr = add_matrix.T\n",
    "\n",
    "# add to main feature matrix\n",
    "X_plus = np.hstack((X.toarray(), mtr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.944567\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 0.839938\n",
      "[3]\tvalid_0's multi_logloss: 0.758092\n",
      "[4]\tvalid_0's multi_logloss: 0.697548\n",
      "[5]\tvalid_0's multi_logloss: 0.646442\n",
      "[6]\tvalid_0's multi_logloss: 0.60251\n",
      "[7]\tvalid_0's multi_logloss: 0.565421\n",
      "[8]\tvalid_0's multi_logloss: 0.53285\n",
      "[9]\tvalid_0's multi_logloss: 0.505212\n",
      "[10]\tvalid_0's multi_logloss: 0.481739\n",
      "[11]\tvalid_0's multi_logloss: 0.460911\n",
      "[12]\tvalid_0's multi_logloss: 0.44248\n",
      "[13]\tvalid_0's multi_logloss: 0.425166\n",
      "[14]\tvalid_0's multi_logloss: 0.410968\n",
      "[15]\tvalid_0's multi_logloss: 0.398369\n",
      "[16]\tvalid_0's multi_logloss: 0.386214\n",
      "[17]\tvalid_0's multi_logloss: 0.375499\n",
      "[18]\tvalid_0's multi_logloss: 0.36629\n",
      "[19]\tvalid_0's multi_logloss: 0.358478\n",
      "[20]\tvalid_0's multi_logloss: 0.351239\n",
      "[21]\tvalid_0's multi_logloss: 0.343743\n",
      "[22]\tvalid_0's multi_logloss: 0.337726\n",
      "[23]\tvalid_0's multi_logloss: 0.332489\n",
      "[24]\tvalid_0's multi_logloss: 0.327161\n",
      "[25]\tvalid_0's multi_logloss: 0.322507\n",
      "[26]\tvalid_0's multi_logloss: 0.317293\n",
      "[27]\tvalid_0's multi_logloss: 0.313994\n",
      "[28]\tvalid_0's multi_logloss: 0.309616\n",
      "[29]\tvalid_0's multi_logloss: 0.305406\n",
      "[30]\tvalid_0's multi_logloss: 0.30182\n",
      "[31]\tvalid_0's multi_logloss: 0.299391\n",
      "[32]\tvalid_0's multi_logloss: 0.295822\n",
      "[33]\tvalid_0's multi_logloss: 0.2929\n",
      "[34]\tvalid_0's multi_logloss: 0.289715\n",
      "[35]\tvalid_0's multi_logloss: 0.286462\n",
      "[36]\tvalid_0's multi_logloss: 0.284559\n",
      "[37]\tvalid_0's multi_logloss: 0.282924\n",
      "[38]\tvalid_0's multi_logloss: 0.280077\n",
      "[39]\tvalid_0's multi_logloss: 0.277589\n",
      "[40]\tvalid_0's multi_logloss: 0.275856\n",
      "[41]\tvalid_0's multi_logloss: 0.274287\n",
      "[42]\tvalid_0's multi_logloss: 0.272537\n",
      "[43]\tvalid_0's multi_logloss: 0.271745\n",
      "[44]\tvalid_0's multi_logloss: 0.270036\n",
      "[45]\tvalid_0's multi_logloss: 0.269267\n",
      "[46]\tvalid_0's multi_logloss: 0.267054\n",
      "[47]\tvalid_0's multi_logloss: 0.266315\n",
      "[48]\tvalid_0's multi_logloss: 0.264612\n",
      "[49]\tvalid_0's multi_logloss: 0.262904\n",
      "[50]\tvalid_0's multi_logloss: 0.262043\n",
      "[51]\tvalid_0's multi_logloss: 0.261048\n",
      "[52]\tvalid_0's multi_logloss: 0.259323\n",
      "[53]\tvalid_0's multi_logloss: 0.258465\n",
      "[54]\tvalid_0's multi_logloss: 0.256924\n",
      "[55]\tvalid_0's multi_logloss: 0.25604\n",
      "[56]\tvalid_0's multi_logloss: 0.254977\n",
      "[57]\tvalid_0's multi_logloss: 0.254755\n",
      "[58]\tvalid_0's multi_logloss: 0.253427\n",
      "[59]\tvalid_0's multi_logloss: 0.252699\n",
      "[60]\tvalid_0's multi_logloss: 0.251931\n",
      "[61]\tvalid_0's multi_logloss: 0.252086\n",
      "[62]\tvalid_0's multi_logloss: 0.251298\n",
      "[63]\tvalid_0's multi_logloss: 0.251144\n",
      "[64]\tvalid_0's multi_logloss: 0.25038\n",
      "[65]\tvalid_0's multi_logloss: 0.249299\n",
      "[66]\tvalid_0's multi_logloss: 0.248684\n",
      "[67]\tvalid_0's multi_logloss: 0.247871\n",
      "[68]\tvalid_0's multi_logloss: 0.247147\n",
      "[69]\tvalid_0's multi_logloss: 0.24623\n",
      "[70]\tvalid_0's multi_logloss: 0.245938\n",
      "[71]\tvalid_0's multi_logloss: 0.245252\n",
      "[72]\tvalid_0's multi_logloss: 0.245121\n",
      "[73]\tvalid_0's multi_logloss: 0.245106\n",
      "[74]\tvalid_0's multi_logloss: 0.244688\n",
      "[75]\tvalid_0's multi_logloss: 0.244145\n",
      "[76]\tvalid_0's multi_logloss: 0.244209\n",
      "[77]\tvalid_0's multi_logloss: 0.243483\n",
      "[78]\tvalid_0's multi_logloss: 0.243177\n",
      "[79]\tvalid_0's multi_logloss: 0.242516\n",
      "[80]\tvalid_0's multi_logloss: 0.241924\n",
      "[81]\tvalid_0's multi_logloss: 0.241053\n",
      "[82]\tvalid_0's multi_logloss: 0.239953\n",
      "[83]\tvalid_0's multi_logloss: 0.240434\n",
      "[84]\tvalid_0's multi_logloss: 0.239697\n",
      "[85]\tvalid_0's multi_logloss: 0.239118\n",
      "[86]\tvalid_0's multi_logloss: 0.238957\n",
      "[87]\tvalid_0's multi_logloss: 0.238477\n",
      "[88]\tvalid_0's multi_logloss: 0.238344\n",
      "[89]\tvalid_0's multi_logloss: 0.238078\n",
      "[90]\tvalid_0's multi_logloss: 0.237648\n",
      "[91]\tvalid_0's multi_logloss: 0.237575\n",
      "[92]\tvalid_0's multi_logloss: 0.237318\n",
      "[93]\tvalid_0's multi_logloss: 0.23682\n",
      "[94]\tvalid_0's multi_logloss: 0.236464\n",
      "[95]\tvalid_0's multi_logloss: 0.236242\n",
      "[96]\tvalid_0's multi_logloss: 0.236661\n",
      "[97]\tvalid_0's multi_logloss: 0.236487\n",
      "[98]\tvalid_0's multi_logloss: 0.236814\n",
      "[99]\tvalid_0's multi_logloss: 0.236491\n",
      "[100]\tvalid_0's multi_logloss: 0.236686\n",
      "[101]\tvalid_0's multi_logloss: 0.236544\n",
      "[102]\tvalid_0's multi_logloss: 0.236426\n",
      "[103]\tvalid_0's multi_logloss: 0.236493\n",
      "[104]\tvalid_0's multi_logloss: 0.236493\n",
      "[105]\tvalid_0's multi_logloss: 0.236272\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's multi_logloss: 0.236242\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_plus, y, test_size=0.33, random_state=42)\n",
    "\n",
    "lgb_train = lightgbm.Dataset(X_train, y_train)\n",
    "lgb_eval = lightgbm.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclassova',\n",
    "    'num_class': 4, \n",
    "    'metric': 'softmax', \n",
    "    'num_leaves': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'feature_fraction': 1.,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5, \n",
    "    'reg_alpha': 3.0,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "start = time.time()\n",
    "gbm = lightgbm.train(params,\n",
    "                     lgb_train,\n",
    "                     num_boost_round=110,\n",
    "                     valid_sets=lgb_eval,\n",
    "                     early_stopping_rounds=10)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train:  0.9400286944045911\n",
      "Accuracy on test:  0.9213744903902155\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on train: ', accuracy_score(y_train, np.argmax(gbm.predict(X_train), axis=1)))\n",
    "print('Accuracy on test: ', accuracy_score(y_test, np.argmax(gbm.predict(X_test), axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gbm.feature_importance());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.944567\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 0.839938\n",
      "[3]\tvalid_0's multi_logloss: 0.758092\n",
      "[4]\tvalid_0's multi_logloss: 0.697548\n",
      "[5]\tvalid_0's multi_logloss: 0.646442\n",
      "[6]\tvalid_0's multi_logloss: 0.60251\n",
      "[7]\tvalid_0's multi_logloss: 0.565421\n",
      "[8]\tvalid_0's multi_logloss: 0.53285\n",
      "[9]\tvalid_0's multi_logloss: 0.505212\n",
      "[10]\tvalid_0's multi_logloss: 0.481739\n",
      "[11]\tvalid_0's multi_logloss: 0.460911\n",
      "[12]\tvalid_0's multi_logloss: 0.44248\n",
      "[13]\tvalid_0's multi_logloss: 0.425166\n",
      "[14]\tvalid_0's multi_logloss: 0.410968\n",
      "[15]\tvalid_0's multi_logloss: 0.398369\n",
      "[16]\tvalid_0's multi_logloss: 0.386214\n",
      "[17]\tvalid_0's multi_logloss: 0.375499\n",
      "[18]\tvalid_0's multi_logloss: 0.36629\n",
      "[19]\tvalid_0's multi_logloss: 0.358478\n",
      "[20]\tvalid_0's multi_logloss: 0.351239\n",
      "[21]\tvalid_0's multi_logloss: 0.343743\n",
      "[22]\tvalid_0's multi_logloss: 0.337726\n",
      "[23]\tvalid_0's multi_logloss: 0.332489\n",
      "[24]\tvalid_0's multi_logloss: 0.327161\n",
      "[25]\tvalid_0's multi_logloss: 0.322507\n",
      "[26]\tvalid_0's multi_logloss: 0.317293\n",
      "[27]\tvalid_0's multi_logloss: 0.313994\n",
      "[28]\tvalid_0's multi_logloss: 0.309616\n",
      "[29]\tvalid_0's multi_logloss: 0.305406\n",
      "[30]\tvalid_0's multi_logloss: 0.30182\n",
      "[31]\tvalid_0's multi_logloss: 0.299391\n",
      "[32]\tvalid_0's multi_logloss: 0.295822\n",
      "[33]\tvalid_0's multi_logloss: 0.2929\n",
      "[34]\tvalid_0's multi_logloss: 0.289715\n",
      "[35]\tvalid_0's multi_logloss: 0.286462\n",
      "[36]\tvalid_0's multi_logloss: 0.284559\n",
      "[37]\tvalid_0's multi_logloss: 0.282924\n",
      "[38]\tvalid_0's multi_logloss: 0.280077\n",
      "[39]\tvalid_0's multi_logloss: 0.277589\n",
      "[40]\tvalid_0's multi_logloss: 0.275856\n",
      "[41]\tvalid_0's multi_logloss: 0.274287\n",
      "[42]\tvalid_0's multi_logloss: 0.272537\n",
      "[43]\tvalid_0's multi_logloss: 0.271745\n",
      "[44]\tvalid_0's multi_logloss: 0.270036\n",
      "[45]\tvalid_0's multi_logloss: 0.269267\n",
      "[46]\tvalid_0's multi_logloss: 0.267054\n",
      "[47]\tvalid_0's multi_logloss: 0.266315\n",
      "[48]\tvalid_0's multi_logloss: 0.264612\n",
      "[49]\tvalid_0's multi_logloss: 0.262904\n",
      "[50]\tvalid_0's multi_logloss: 0.262043\n",
      "[51]\tvalid_0's multi_logloss: 0.261048\n",
      "[52]\tvalid_0's multi_logloss: 0.259323\n",
      "[53]\tvalid_0's multi_logloss: 0.258465\n",
      "[54]\tvalid_0's multi_logloss: 0.256924\n",
      "[55]\tvalid_0's multi_logloss: 0.25604\n",
      "[56]\tvalid_0's multi_logloss: 0.254977\n",
      "[57]\tvalid_0's multi_logloss: 0.254755\n",
      "[58]\tvalid_0's multi_logloss: 0.253427\n",
      "[59]\tvalid_0's multi_logloss: 0.252699\n",
      "[60]\tvalid_0's multi_logloss: 0.251931\n",
      "[61]\tvalid_0's multi_logloss: 0.252086\n",
      "[62]\tvalid_0's multi_logloss: 0.251298\n",
      "[63]\tvalid_0's multi_logloss: 0.251144\n",
      "[64]\tvalid_0's multi_logloss: 0.25038\n",
      "[65]\tvalid_0's multi_logloss: 0.249299\n",
      "[66]\tvalid_0's multi_logloss: 0.248684\n",
      "[67]\tvalid_0's multi_logloss: 0.247871\n",
      "[68]\tvalid_0's multi_logloss: 0.247147\n",
      "[69]\tvalid_0's multi_logloss: 0.24623\n",
      "[70]\tvalid_0's multi_logloss: 0.245938\n",
      "[71]\tvalid_0's multi_logloss: 0.245252\n",
      "[72]\tvalid_0's multi_logloss: 0.245121\n",
      "[73]\tvalid_0's multi_logloss: 0.245106\n",
      "[74]\tvalid_0's multi_logloss: 0.244688\n",
      "[75]\tvalid_0's multi_logloss: 0.244145\n",
      "[76]\tvalid_0's multi_logloss: 0.244209\n",
      "[77]\tvalid_0's multi_logloss: 0.243483\n",
      "[78]\tvalid_0's multi_logloss: 0.243177\n",
      "[79]\tvalid_0's multi_logloss: 0.242516\n",
      "[80]\tvalid_0's multi_logloss: 0.241924\n",
      "[81]\tvalid_0's multi_logloss: 0.241053\n",
      "[82]\tvalid_0's multi_logloss: 0.239953\n",
      "[83]\tvalid_0's multi_logloss: 0.240434\n",
      "[84]\tvalid_0's multi_logloss: 0.239697\n",
      "[85]\tvalid_0's multi_logloss: 0.239118\n",
      "[86]\tvalid_0's multi_logloss: 0.238957\n",
      "[87]\tvalid_0's multi_logloss: 0.238477\n",
      "[88]\tvalid_0's multi_logloss: 0.238344\n",
      "[89]\tvalid_0's multi_logloss: 0.238078\n",
      "[90]\tvalid_0's multi_logloss: 0.237648\n",
      "[91]\tvalid_0's multi_logloss: 0.237575\n",
      "[92]\tvalid_0's multi_logloss: 0.237318\n",
      "[93]\tvalid_0's multi_logloss: 0.23682\n",
      "[94]\tvalid_0's multi_logloss: 0.236464\n",
      "[95]\tvalid_0's multi_logloss: 0.236242\n",
      "[96]\tvalid_0's multi_logloss: 0.236485\n",
      "[97]\tvalid_0's multi_logloss: 0.236429\n",
      "[98]\tvalid_0's multi_logloss: 0.236537\n",
      "[99]\tvalid_0's multi_logloss: 0.236159\n",
      "[100]\tvalid_0's multi_logloss: 0.236224\n",
      "[101]\tvalid_0's multi_logloss: 0.235798\n",
      "[102]\tvalid_0's multi_logloss: 0.236042\n",
      "[103]\tvalid_0's multi_logloss: 0.235623\n",
      "[104]\tvalid_0's multi_logloss: 0.23586\n",
      "[105]\tvalid_0's multi_logloss: 0.23581\n",
      "[106]\tvalid_0's multi_logloss: 0.23588\n",
      "[107]\tvalid_0's multi_logloss: 0.235964\n",
      "[108]\tvalid_0's multi_logloss: 0.236123\n",
      "[109]\tvalid_0's multi_logloss: 0.236092\n",
      "[110]\tvalid_0's multi_logloss: 0.236334\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[103]\tvalid_0's multi_logloss: 0.235623\n"
     ]
    }
   ],
   "source": [
    "features_mask = gbm.feature_importance() != 0\n",
    "\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X_plus[:, features_mask], y, \n",
    "                                                            test_size=0.33, \n",
    "                                                            random_state=42)\n",
    "\n",
    "lgb_train_p = lightgbm.Dataset(X_train_p, y_train_p)\n",
    "lgb_eval_p = lightgbm.Dataset(X_test_p, y_test_p, reference=lgb_train_p)\n",
    "\n",
    "start_p = time.time()\n",
    "gbm_p = lightgbm.train(params,\n",
    "                       lgb_train_p,\n",
    "                       num_boost_round=110,\n",
    "                       valid_sets=lgb_eval_p,\n",
    "                       early_stopping_rounds=10)\n",
    "\n",
    "end_p = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train:  0.942467718794835\n",
      "Accuracy on test:  0.9210832847990681\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on train: ', accuracy_score(y_train, np.argmax(gbm_p.predict(X_train_p), axis=1)))\n",
    "print('Accuracy on test: ', accuracy_score(y_test, np.argmax(gbm_p.predict(X_test_p), axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Make predictions on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df1_new = pd.read_excel('Общий файл отзывов_4_1.xlsx')\n",
    "df2_new = pd.read_excel('Общий файл отзывов_4_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(df_list):\n",
    "    # union df's along columns and deleting useless column\n",
    "    data_new = pd.concat(df_list, axis=0, ignore_index=True)\n",
    "    data_new.drop(columns='index', inplace=True)\n",
    "    \n",
    "    # deleting NA\n",
    "    data_new.fillna('', inplace=True)\n",
    "    \n",
    "    # creating bag of docs\n",
    "    corpus_new = []\n",
    "    for i in range(data_new.shape[0]):\n",
    "        corpus_new.append(data_new.iloc[i, 0])\n",
    "    \n",
    "    \n",
    "    X_new = vectorizer.transform(corpus_new)\n",
    "        \n",
    "    add_matrix_new = [0] * len(corpus_new)\n",
    "    for pattern in all_patterns:\n",
    "        tmp_feature = [0] * len(corpus_new)\n",
    "        for i in range(len(corpus_new)):\n",
    "            f = len(re.findall(pattern, corpus_new[i]))\n",
    "            if f > 0:\n",
    "                tmp_feature[i] = f\n",
    "        add_matrix_new = np.vstack((add_matrix_new, tmp_feature))\n",
    "        \n",
    "        \n",
    "    add_matrix_new = add_matrix_new[1:, :]\n",
    "    mtr_new = add_matrix_new.T\n",
    "    return np.hstack((X_new.toarray(), mtr_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred1 = []\n",
    "step = 10000\n",
    "for i in range(0, df1_new.shape[0], step):\n",
    "    x_tmp = prepare_data([df1_new.iloc[i:i + step, :]]) #[:, features_mask]\n",
    "    pred1.extend(np.argmax(gbm.predict(x_tmp), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred2 = []\n",
    "step = 10000\n",
    "for i in range(0, df2_new.shape[0], step):\n",
    "    x_tmp = prepare_data([df2_new.iloc[i:i + step, :]]) #[:, features_mask]\n",
    "    pred2.extend(np.argmax(gbm.predict(x_tmp), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 38998, 0: 523, 2: 4203, 1: 1274})"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({3: 44711, 0: 484, 2: 2592, 1: 1552})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.savetxt('review_predictions_4_2_1.csv', pred1, delimiter=',', fmt='%.2i')\n",
    "np.savetxt('review_predictions_4_2_2.csv', pred2, delimiter=',', fmt='%.2i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
